{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 34,
>>>>>>> a42666f457c2b30e0e1b9220d2e355082231dd78
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data, predict_labels, create_csv_submission\n",
    "from implementations import least_squares, least_squares_GD, least_squares_SGD, compute_loss_ls, ridge_regression, ridge_GD, ridge_SGD, logistic_regression, reg_logistic_regression\n",
    "from preprocessing import standardize_train, standardize_test, add_bias\n",
    "from other import remove_999\n",
    "from plots import plot_train_test\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, input_train, ids_train = load_csv_data('train.csv', sub_sample=False)\n",
    "y_test, input_test, ids_test = load_csv_data('test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Careful to standardize the x_test with the mean and std of x_train\n",
    "x_train_no_999, y_train_no_999 = remove_999(input_train, y_train)\n",
    "\n",
    "x_train_no_999, mean, std = standardize_train(x_train_no_999)\n",
    "x_train_no_999 = add_bias(x_train_no_999)\n",
    "\n",
    "x_test = standardize_test(input_test, mean, std)\n",
    "x_test = add_bias(x_test)   ###### Verifier si il faut add bias au test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68114\n",
      "(68114,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_no_999.shape[0])\n",
    "print(y_train_no_999.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm. (probably change afterwards)\n",
    "max_iters = 200   #les plots sont moches parce que j'ai fait avec 20 ici                                  \n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.random.rand(x_train_no_999.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For grid search of hyperparameters\n",
    "num_intervals = 10\n",
    "gammas = np.linspace(0.005, 0.35, num_intervals)\n",
    "#gammas = np.array([0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\n",
    "#lambdas = np.logspace(-4, -0.05, num_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w, x_test, y_test):\n",
    "    y_pred = predict_labels(-w, x_test)\n",
    "    accuracy = sum(y_pred == y_test)/len(y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ls, _ = least_squares(y_train_no_999, x_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "accuracy_ls = accuracy(w_ls, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657886308201845"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ls_gd_hyperparam(gammas, nb_fold, x_train, y_train):\n",
    "    #print(\"y {}\".format(y_train))\n",
    "    loss_valid = np.zeros([len(gammas), nb_fold])\n",
    "    loss_train = np.zeros([len(gammas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for k in range(nb_fold):\n",
    "            x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "            y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "            \n",
    "            x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "            y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "                                        \n",
    "            w, loss_tr = least_squares_GD(y_train_k, x_train_k, w_initial, max_iters, gamma)\n",
    "            loss_train[i][k] = loss_tr\n",
    "            loss_valid[i][k] = compute_loss_ls(y_valid_k, x_valid_k, w)\n",
    "            \n",
    "    return loss_valid, loss_train "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
=======
   "execution_count": 40,
>>>>>>> a42666f457c2b30e0e1b9220d2e355082231dd78
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_valid_gd, loss_train_gd = ls_gd_hyperparam(gammas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gd_mean = np.mean(loss_train_gd, axis=1)\n",
    "valid_gd_mean = np.mean(loss_valid_gd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5e2790b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_test(train_gd_mean, valid_gd_mean, gammas)  #le chiffre est max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311666666667\n",
      "0.368278298409\n"
     ]
    }
   ],
   "source": [
    "# Minimum values for ls_gd\n",
    "idx = np.argmin(valid_gd_mean)\n",
    "learning_rate = gammas[idx]\n",
    "ls_gd_loss = np.min(valid_gd_mean)\n",
    "print(learning_rate)\n",
    "print(ls_gd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ls_sgd_hyperparam(gammas, nb_fold, x_train, y_train):\n",
    "    loss_valid = np.zeros([len(gammas), nb_fold])\n",
    "    loss_train = np.zeros([len(gammas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for k in range(nb_fold):\n",
    "            x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "            y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "            \n",
    "            x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "            y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "                                        \n",
    "            w, loss_tr = least_squares_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma)\n",
    "            loss_train[i][k] = loss_tr\n",
    "            loss_valid[i][k] = compute_loss_ls(y_valid_k, x_valid_k, w)\n",
    "            \n",
    "    return loss_valid, loss_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_valid_sgd, loss_train_sgd = ls_sgd_hyperparam(gammas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sgd_mean = np.mean(loss_train_sgd, axis=1)\n",
    "valid_sgd_mean = np.mean(loss_valid_sgd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_train_test(train_sgd_mean, valid_sgd_mean, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "idx = np.argmin(valid_sgd_mean)\n",
    "learning_rate = gammas[idx]\n",
    "ls_sgd_loss = np.min(valid_sgd_mean)\n",
    "print(learning_rate)\n",
    "print(ls_sgd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peut etre trop long, plutot voir si on pose un 'bon' gamma, quel est le meilleur lambda.\n",
    "\n",
    "Du coup, même fonction que avant pour hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_sgd_hyperparam(gammas, lambdas, nb_fold, x_train, y_train):\n",
    "    loss_train = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    loss_valid = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, lambda_ in enumerate(lambdas):\n",
    "            for k in range(nb_fold):\n",
    "                x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "                y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "\n",
    "                x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "                y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "\n",
    "                w, loss_gamma = ridge_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma, lambda_)\n",
    "                loss_train[i][j][k] = loss_gamma\n",
    "                loss_valid[i][j][k]  = compute_loss_ridge(y_valid_k, x_valid_k, w, lambda_)\n",
    "                print(\"fold {}  \".format(k))\n",
    "            print(\"lambda {}\\n\".format(j))\n",
    "        print(\"gamma {} \\n \\n\".format(i))\n",
    "    return loss_train, loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_valid_r_sgd, loss_train_r_sgd = ridge_sgd_hyperparam(gammas, lambdas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sgd_mean = np.mean(loss_train_r_sgd, axis=2)\n",
    "valid_sgd_mean = np.mean(loss_valid_r_sgd, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_valid_r_sgd[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Plot 2D à coder   TO TEST\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FixedLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "X = gammas\n",
    "Y = lambdas\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = valid_sgd_mean\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,\n",
    "        linewidth=0, antialiased=False)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "ax.set_xlabel('Gammas', fontsize=15)\n",
    "ax.set_ylabel('Lambdas', fontsize=15)\n",
    "ax.set_zlabel('Loss', fontsize=15)\n",
    "#plt.savefig('hyperparam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "ind = np.unravel_index(np.argmin(valid_sgd_mean, axis=None), valid_sgd_mean.shape)\n",
    "learning_rate = gammas[ind[0]]\n",
    "ls_sgd_loss = valid_sgd_mean[ind]\n",
    "print(learning_rate)\n",
    "print(ls_sgd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_gd_hyperparam(gammas, lambdas, nb_fold, x_train, y_train):\n",
    "    loss_train = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    loss_valid = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, lambda_ in enumerate(lambdas):\n",
    "            for k in range(nb_fold):\n",
    "                \n",
    "                x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "                y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "\n",
    "                x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "                y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "\n",
    "                w, loss_gamma = ridge_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma, lambda_)\n",
    "                loss_train[i][j][k] = loss_gamma\n",
    "                loss_valid[i][j][k] = compute_loss_ridge(y_valid_k, x_valid_k, w, lambda_)\n",
    "                \n",
    "    return loss_train, loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_valid_r_gd, loss_train_r_gd = ridge_gd_hyperparam(gammas, lambdas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gd_mean = np.mean(loss_train_r_gd, axis=2)\n",
    "valid_gd_mean = np.mean(loss_valid_r_gd, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "ind = np.unravel_index(np.argmin(valid_gd_mean, axis=None), valid_gd_mean.shape)\n",
    "learning_rate = gammas[ind[0]]\n",
    "ls_gd_loss = valid_gd_mean[ind]\n",
    "print(learning_rate)\n",
    "print(ls_gd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pas sûre des logistic regression. Voir correction lab05\n",
    "Sinon toujours le même code et techniques que avant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Debugged but not sure from here: Il y aura probablement une correction du labo 5 pour améliorer / vérifier les fonctions de logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction de chaque méthode pour Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
