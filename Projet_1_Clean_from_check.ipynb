{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data, predict_labels, create_csv_submission\n",
    "from implementations import least_squares, least_squares_GD, least_squares_SGD, compute_loss_ls, ridge_regression, ridge_GD, ridge_SGD, logistic_regression, reg_logistic_regression\n",
    "from preprocessing import standardize_train, standardize_test, add_bias\n",
    "from other import remove_999\n",
    "from plots import plot_train_test\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, input_train, ids_train = load_csv_data('train.csv', sub_sample=False)\n",
    "y_test, input_test, ids_test = load_csv_data('test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful to standardize the x_test with the mean and std of x_train\n",
    "x_train_no_999, y_train_no_999 = remove_999(input_train, y_train)\n",
    "\n",
    "x_train_no_999, mean, std = standardize_train(x_train_no_999)\n",
    "x_train_no_999 = add_bias(x_train_no_999)\n",
    "\n",
    "x_test = standardize_test(input_test, mean, std)\n",
    "x_test = add_bias(x_test)   ###### Verifier si il faut add bias au test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68114\n",
      "(68114,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_no_999.shape[0])\n",
    "print(y_train_no_999.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm. (probably change afterwards)\n",
    "max_iters = 1000   #les plots sont moches parce que j'ai fait avec 20 ici                                  \n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.random.rand(x_train_no_999.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For grid search of hyperparameters\n",
    "num_intervals = 10\n",
    "gammas = np.linspace(0.005, 0.2, num_intervals)\n",
    "#gammas = np.array([0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\n",
    "#lambdas = np.logspace(-4, -0.05, num_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w, x_test, y_test):\n",
    "    y_pred = predict_labels(-w, x_test)\n",
    "    accuracy = sum(y_pred == y_test)/len(y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ls, _ = least_squares(y_train_no_999, x_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "accuracy_ls = accuracy(w_ls, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657886308201845"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_gd_hyperparam(gammas, nb_fold, x_train, y_train):\n",
    "    #print(\"y {}\".format(y_train))\n",
    "    loss_valid = np.zeros([len(gammas), nb_fold])\n",
    "    loss_train = np.zeros([len(gammas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for k in range(nb_fold):\n",
    "            x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "            y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "            \n",
    "            x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "            y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "                                        \n",
    "            w, loss_tr = least_squares_GD(y_train_k, x_train_k, w_initial, max_iters, gamma)\n",
    "            loss_train[i][k] = loss_tr\n",
    "            loss_valid[i][k] = compute_loss_ls(y_valid_k, x_valid_k, w)\n",
    "            \n",
    "    return loss_valid, loss_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_valid_gd, loss_train_gd = ls_gd_hyperparam(gammas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gd_mean = np.mean(loss_train_gd, axis=1)\n",
    "valid_gd_mean = np.mean(loss_valid_gd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b5667634e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_test(train_gd_mean, valid_gd_mean, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.36820105888729493\n"
     ]
    }
   ],
   "source": [
    "# Minimum values for ls_gd\n",
    "idx = np.argmin(valid_gd_mean)\n",
    "learning_rate = gammas[idx]\n",
    "ls_gd_loss = np.min(valid_gd_mean)\n",
    "print(learning_rate)\n",
    "print(ls_gd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_sgd_hyperparam(gammas, nb_fold, x_train, y_train):\n",
    "    loss_valid = np.zeros([len(gammas), nb_fold])\n",
    "    loss_train = np.zeros([len(gammas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for k in range(nb_fold):\n",
    "            x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "            y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "            \n",
    "            x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "            y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "                                        \n",
    "            w, loss_tr = least_squares_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma)\n",
    "            loss_train[i][k] = loss_tr\n",
    "            loss_valid[i][k] = compute_loss_ls(y_valid_k, x_valid_k, w)\n",
    "            \n",
    "    return loss_valid, loss_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valid_sgd, loss_train_sgd = ls_sgd_hyperparam(gammas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sgd_mean = np.mean(loss_train_sgd, axis=1)\n",
    "valid_sgd_mean = np.mean(loss_valid_sgd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test(train_sgd_mean, valid_sgd_mean, gammas, \"Least squares SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "idx = np.argmin(valid_sgd_mean)\n",
    "learning_rate = gammas[idx]\n",
    "ls_sgd_loss = np.min(valid_sgd_mean)\n",
    "print(learning_rate)\n",
    "print(ls_sgd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peut etre trop long, plutot voir si on pose un 'bon' gamma, quel est le meilleur lambda.\n",
    "\n",
    "Du coup, même fonction que avant pour hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_sgd_hyperparam(gammas, lambdas, nb_fold, x_train, y_train):\n",
    "    loss_train = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    loss_valid = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, lambda_ in enumerate(lambdas):\n",
    "            for k in range(nb_fold):\n",
    "                x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "                y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "\n",
    "                x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "                y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "\n",
    "                w, loss_gamma = ridge_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma, lambda_)\n",
    "                loss_train[i][j][k] = loss_gamma\n",
    "                loss_valid[i][j][k]  = compute_loss_ridge(y_valid_k, x_valid_k, w, lambda_)\n",
    "                print(\"fold {}  \".format(k))\n",
    "            print(\"lambda {}\\n\".format(j))\n",
    "        print(\"gamma {} \\n \\n\".format(i))\n",
    "    return loss_train, loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valid_r_sgd, loss_train_r_sgd = ridge_sgd_hyperparam(gammas, lambdas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sgd_mean = np.mean(loss_train_r_sgd, axis=2)\n",
    "valid_sgd_mean = np.mean(loss_valid_r_sgd, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valid_r_sgd[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot 2D à coder   TO TEST\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FixedLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "X = gammas\n",
    "Y = lambdas\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = valid_sgd_mean\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,\n",
    "        linewidth=0, antialiased=False)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "ax.set_xlabel('Gammas', fontsize=15)\n",
    "ax.set_ylabel('Lambdas', fontsize=15)\n",
    "ax.set_zlabel('Loss', fontsize=15)\n",
    "#plt.savefig('hyperparam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "ind = np.unravel_index(np.argmin(valid_sgd_mean, axis=None), valid_sgd_mean.shape)\n",
    "learning_rate = gammas[ind[0]]\n",
    "ls_sgd_loss = valid_sgd_mean[ind]\n",
    "print(learning_rate)\n",
    "print(ls_sgd_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_gd_hyperparam(gammas, lambdas, nb_fold, x_train, y_train):\n",
    "    loss_train = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    loss_valid = np.zeros([len(gammas), len(lambdas), nb_fold])\n",
    "    \n",
    "    nb_elem = math.floor(x_train.shape[0]/nb_fold)\n",
    "    \n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, lambda_ in enumerate(lambdas):\n",
    "            for k in range(nb_fold):\n",
    "                \n",
    "                x_valid_k = x_train[k*nb_elem:(k+1)*nb_elem][:]  \n",
    "                y_valid_k = y_train[k*nb_elem:(k+1)*nb_elem]\n",
    "\n",
    "                x_train_k = np.concatenate([x_train[0:k*nb_elem][:], x_train[(k+1)*nb_elem:][:]])\n",
    "                y_train_k = np.concatenate([y_train[0:k*nb_elem],    y_train[(k+1)*nb_elem:]   ]) \n",
    "\n",
    "                w, loss_gamma = ridge_SGD(y_train_k, x_train_k, w_initial, max_iters, gamma, lambda_)\n",
    "                loss_train[i][j][k] = loss_gamma\n",
    "                loss_valid[i][j][k] = compute_loss_ridge(y_valid_k, x_valid_k, w, lambda_)\n",
    "                \n",
    "    return loss_train, loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valid_r_gd, loss_train_r_gd = ridge_gd_hyperparam(gammas, lambdas, nb_fold, x_train_no_999, y_train_no_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gd_mean = np.mean(loss_train_r_gd, axis=2)\n",
    "valid_gd_mean = np.mean(loss_valid_r_gd, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum values for ls_sgd\n",
    "ind = np.unravel_index(np.argmin(valid_gd_mean, axis=None), valid_gd_mean.shape)\n",
    "learning_rate = gammas[ind[0]]\n",
    "ls_gd_loss = valid_gd_mean[ind]\n",
    "print(learning_rate)\n",
    "print(ls_gd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pas sûre des logistic regression. Voir correction lab05\n",
    "Sinon toujours le même code et techniques que avant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Debugged but not sure from here: Il y aura probablement une correction du labo 5 pour améliorer / vérifier les fonctions de logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction de chaque méthode pour Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
